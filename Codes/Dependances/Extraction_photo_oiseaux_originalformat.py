import os
import requests
import geopandas as gpd
import climatsEtHabitats


# Dossier parent pour toutes les esp√®ces d'oiseaux
dataset_dir = '/Donnees/birds_dataset'
os.makedirs(dataset_dir, exist_ok=True)

# Shapefile pour les climats
shapefile_climats = gpd.read_file("/Donnees/climates/climates.shp")

# Shapefile pour les ecoregions
shapefile_ecoregions = gpd.read_file("/Donnees/Ecoregions/wwf_terr_ecos.shp")

raster_ecosystemes = "/Donnees/Ecosystemes/raster"

# Csv avonet pour les habitats
avonet = "/Donnees/avonet/AVONET2_eBird.xlsx"
sheet_name = "AVONET2_eBird"

# Nombre d'esp√®ces et d'images par esp√®ce
num_species = 1000
num_images_per_species = 10


# Fonction pour r√©cup√©rer les esp√®ces d'oiseaux
def get_bird_species():
    species_list = []
    page = 1

    while len(species_list) < num_species:
        url = "https://api.inaturalist.org/v1/taxa"
        params = {
            'taxon_id': 3,  # ID taxonomique pour la classe "Aves"
            'rank': 'species',
            'per_page': 100,  # Nombre d'esp√®ces par page
            'page': page
        }

        response = requests.get(url, params=params)
        if response.status_code == 200:
            data = response.json()
            if 'results' in data:
                species_list.extend(data['results'])
            else:
                break
        else:
            print(f"Erreur lors de la r√©cup√©ration des esp√®ces : {response.status_code}")
            break

        # Arr√™ter si moins de 100 r√©sultats sont retourn√©s (fin des r√©sultats)
        if len(data['results']) < 100:
            break

        page += 1

    return species_list[:num_species]

def download_images_for_species(taxon_id, species_name):
    observations = []
    page = 1

    while len(observations) < num_images_per_species:
        url = "https://api.inaturalist.org/v1/observations"
        params = {
            'taxon_id': taxon_id,
            'per_page': 100,
            'page': page,
            'order_by': 'created_at'
        }

        response = requests.get(url, params=params)

        if response.status_code == 200:
            data = response.json()
            if 'results' in data:
                observations.extend(data['results'])
            else:
                break
        else:
            print(f"Erreur lors de la r√©cup√©ration des observations pour {species_name}. Statut: {response.status_code}")
            break

        if len(data['results']) < 100:
            break

        page += 1

    print(f"Nombre d'observations r√©cup√©r√©es pour {species_name}: {len(observations)}")

    # Garder les `num_images_per_species` premi√®res observations
    observations = observations[:num_images_per_species]

    # Extraire et t√©l√©charger les photos sp√©cifiques √† chaque observation
    photo_urls = []
    coordinates = []

    for obs in observations:
        # V√©rification si 'obs' est un dictionnaire valide
        if obs and isinstance(obs, dict):
            geojson_coords = obs.get('geojson', {}).get('coordinates', None)

            if geojson_coords:  # V√©rifie si des coordonn√©es sont disponibles
                longitude, latitude = geojson_coords  # Les coordonn√©es sont dans l'ordre [longitude, latitude]
                coordinates.append((latitude, longitude))  # Ajoute les coordonn√©es √† la liste
            else:
                print(f"Aucune coordonn√©e disponible pour l'observation {obs.get('id', 'ID inconnu')}")
        else:
            print(f"Observation invalide ou mal format√©e pour {species_name}")

        # V√©rifie si 'photos' existe et contient des donn√©es
        if 'photos' in obs:
            for photo in obs['photos']:
                # Utiliser l'URL de la photo existante et ajouter "original" au bon format
                base_url = photo['url'].rsplit('/', 1)[0]  # R√©cup√®re la base de l'URL
                if photo['url'].endswith(".jpg") or photo['url'].endswith(".jpeg"):
                    # Ajouter "original" √† l'URL pour t√©l√©charger la version originale
                    photo_url = f"{base_url}/original.jpg" if photo['url'].endswith(".jpg") else f"{base_url}/original.jpeg"
                    print(f"T√©l√©chargement de l'image : {photo_url}")
                    photo_urls.append(photo_url)

    # Limiter aux `num_images_per_species`
    photo_urls = photo_urls[:num_images_per_species]

    # Cr√©er un sous-dossier pour l'esp√®ce
    if photo_urls:
        species_dir = os.path.join(dataset_dir, species_name)
        os.makedirs(species_dir, exist_ok=True)

        # T√©l√©charger les images, g√©rer les erreurs pour chaque image
        for i, url in enumerate(photo_urls):
            try:
                # Extraire l'extension du fichier √† partir de l'URL (ex: .jpg, .png)
                file_extension = url.split('.')[-1]
                response = requests.get(url)
                response.raise_for_status()  # L√®ve une exception si le t√©l√©chargement √©choue
                with open(f'{species_dir}/{species_name}_{i+1}.{file_extension}', 'wb') as f:
                    f.write(response.content)
            except Exception as e:
                print(f"Erreur lors du t√©l√©chargement de l'image {i+1} pour {species_name}: {e}")
                continue  # Passer √† l'image suivante m√™me en cas d'erreur

    # Appel des fonctions pour r√©cup√©rer le climat, le(s) ecosyst√®me(s), l'habitat et l'√©cor√©gion associ√©s aux coordonn√©es de l'observation
    if coordinates:
        print(f"üìç Lancement de l'analyse g√©ospatiale pour {species_name}")
        climatsEtHabitats.climats(coordinates, shapefile_climats, species_name, dataset_dir)
        print(f"‚úÖ Climat OK pour {species_name}")
        climatsEtHabitats.ecoregions(coordinates, shapefile_ecoregions, species_name, dataset_dir)
        print(f"‚úÖ √âcor√©gions OK pour {species_name}") 
        
        
        #try:
            #climatsEtHabitats.ecosystemes(coordinates, raster_ecosystemes, species_name, dataset_dir)
            #print(f"‚úÖ √âcosyst√®mes OK pour {species_name}")
        #except Exception as e:
            #print(f"‚ùå Erreur dans ecosystemes() pour {species_name} : {e}")

    
    print(f"üìä Appel √† AVONET pour {species_name}")
    climatsEtHabitats.avonet_habitats(avonet, sheet_name, species_name, dataset_dir)
    print(f"‚úÖ AVONET OK pour {species_name}")
    

# R√©cup√©rer les premi√®res `num_species` esp√®ces d'oiseaux
bird_species = get_bird_species()

# T√©l√©charger les images pour chaque esp√®ce d'oiseau
# R√©cup√©rer les premi√®res `num_species` esp√®ces d'oiseaux
bird_species = get_bird_species()

# T√©l√©charger les images pour chaque esp√®ce d'oiseau
for species in bird_species:
    species_name = species['name'].replace(" ", "_")  # Nom de l'esp√®ce
    taxon_id = species['id']  # ID taxonomique de l'esp√®ce
    print(f"T√©l√©chargement des images pour {species_name}...")
    
    try:
        download_images_for_species(taxon_id, species_name)  # T√©l√©charger les images pour l'esp√®ce
    except Exception as e:
        print(f"Erreur lors du t√©l√©chargement des images pour {species_name}: {e}")
        continue  # Passer √† l'esp√®ce suivante en cas d'erreur

print("T√©l√©chargement des images termin√©.")

